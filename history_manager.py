"""
è¯„æµ‹ç»“æœå†å²ç®¡ç†ç³»ç»Ÿ
æä¾›ä¸“ä¸šçš„ç»“æœå­˜å‚¨ã€æ£€ç´¢ã€æ ‡ç­¾ç®¡ç†åŠŸèƒ½
"""

import os
import shutil
import json
from datetime import datetime
from typing import List, Dict, Optional
from database import db
import pandas as pd

class EvaluationHistoryManager:
    def __init__(self):
        self.results_dir = "results_history"
        self.ensure_directories()
    
    def ensure_directories(self):
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        os.makedirs(self.results_dir, exist_ok=True)
        os.makedirs(os.path.join(self.results_dir, "archived"), exist_ok=True)
    
    def save_evaluation_result(self, 
                             evaluation_data: Dict,
                             result_file_path: str,
                             project_id: str = None) -> str:
        """
        ä¿å­˜è¯„æµ‹ç»“æœåˆ°å†å²è®°å½•
        
        Args:
            evaluation_data: è¯„æµ‹å…ƒæ•°æ®
            result_file_path: ç»“æœæ–‡ä»¶è·¯å¾„
            project_id: é¡¹ç›®ID
        
        Returns:
            result_id: ä¿å­˜çš„ç»“æœID
        """
        try:
            # è·å–æˆ–ç”Ÿæˆç»“æœåç§°
            custom_name = evaluation_data.get('custom_name', '').strip()
            
            if custom_name:
                # ä½¿ç”¨è‡ªå®šä¹‰åç§°ï¼Œå¹¶æ·»åŠ æ—¶é—´æˆ³ä»¥é¿å…å†²çª
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                result_name = f"{custom_name}_{timestamp}"
            else:
                # è‡ªåŠ¨ç”Ÿæˆç»“æœåç§°
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                dataset_name = os.path.splitext(os.path.basename(evaluation_data.get('dataset_file', 'unknown')))[0]
                models_str = "_".join(evaluation_data.get('models', []))[:50]  # é™åˆ¶é•¿åº¦
                result_name = f"{dataset_name}_{models_str}_{timestamp}"
            
            # å¤åˆ¶ç»“æœæ–‡ä»¶åˆ°å†å²ç›®å½•
            result_filename = f"{result_name}.csv"
            dest_path = os.path.join(self.results_dir, result_filename)
            shutil.copy2(result_file_path, dest_path)
            
            # ç”Ÿæˆç»“æœæ‘˜è¦
            result_summary = self._generate_result_summary(result_file_path, evaluation_data)
            
            # è‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾
            tags = self._generate_auto_tags(evaluation_data, result_summary)
            
            # ä¿å­˜å®Œæ•´çš„è¯„æµ‹å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬æ—¶é—´ä¿¡æ¯ç”¨äºæŒä¹…åŒ–åˆ†æ
            metadata = {
                'start_time': evaluation_data.get('start_time'),
                'end_time': evaluation_data.get('end_time'),
                'question_count': evaluation_data.get('question_count', 0),
                'evaluation_settings': {
                    'mode': evaluation_data.get('evaluation_mode', 'unknown'),
                    'models': evaluation_data.get('models', []),
                    'dataset_name': os.path.splitext(os.path.basename(evaluation_data.get('dataset_file', '')))[0]
                },
                'analysis_generated': False  # æ ‡è®°æ˜¯å¦å·²ç”Ÿæˆåˆ†ææ•°æ®
            }
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            result_id = db.save_evaluation_result(
                project_id=project_id or self._get_default_project_id(),
                name=result_name,
                dataset_file=evaluation_data.get('dataset_file', ''),
                models=evaluation_data.get('models', []),
                result_file=dest_path,
                evaluation_mode=evaluation_data.get('evaluation_mode', 'unknown'),
                result_summary=result_summary,
                tags=tags,
                created_by=evaluation_data.get('created_by', 'system'),
                metadata=metadata
            )
            
            print(f"âœ… è¯„æµ‹ç»“æœå·²ä¿å­˜: {result_id}")
            return result_id
            
        except Exception as e:
            print(f"âŒ ä¿å­˜è¯„æµ‹ç»“æœå¤±è´¥: {e}")
            raise
    
    def get_history_list(self, 
                        project_id: str = None,
                        tags: List[str] = None,
                        limit: int = 20,
                        offset: int = 0,
                        created_by: str = None,
                        include_all_users: bool = False) -> Dict:
        """è·å–å†å²è®°å½•åˆ—è¡¨ï¼ˆæ”¯æŒç”¨æˆ·æƒé™è¿‡æ»¤ï¼‰"""
        try:
            results = db.get_evaluation_history(
                project_id=project_id,
                tags=tags,
                limit=limit,
                offset=offset,
                created_by=created_by,
                include_all_users=include_all_users
            )
            
            # æ·»åŠ æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥å’Œé¢å¤–ä¿¡æ¯
            for result in results:
                result['file_exists'] = os.path.exists(result['result_file'])
                result['file_size'] = self._get_file_size(result['result_file'])
                result['download_url'] = f"/api/history/download/{result['id']}"
                result['view_url'] = f"/view_history/{result['id']}"
                # æ ‡æ³¨åŠŸèƒ½å·²ç§»é™¤
                
                # æ·»åŠ åˆ›å»ºè€…ä¿¡æ¯
                if result.get('created_by'):
                    creator_info = db.get_user_by_id(result['created_by'])
                    result['creator_name'] = creator_info['display_name'] if creator_info else 'æœªçŸ¥ç”¨æˆ·'
                    result['creator_username'] = creator_info['username'] if creator_info else 'unknown'
                else:
                    result['creator_name'] = 'ç³»ç»Ÿ'
                    result['creator_username'] = 'system'
            
            return {
                'success': True,
                'results': results,
                'total': len(results),
                'has_more': len(results) == limit
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'results': []
            }
    
    def get_result_detail(self, result_id: str) -> Dict:
        """è·å–å•ä¸ªç»“æœçš„è¯¦ç»†ä¿¡æ¯"""
        try:
            results = db.get_evaluation_history()
            result = next((r for r in results if r['id'] == result_id), None)
            
            if not result:
                return {'success': False, 'error': 'ç»“æœä¸å­˜åœ¨'}
            
            # è¯»å–ç»“æœæ–‡ä»¶å†…å®¹
            if os.path.exists(result['result_file']):
                df = pd.read_csv(result['result_file'])
                result['data_preview'] = df.head(10).to_dict('records')
                result['total_rows'] = len(df)
                result['columns'] = df.columns.tolist()
            
            # æ ‡æ³¨åŠŸèƒ½å·²ç§»é™¤
            result['annotations'] = []
            result['annotation_count'] = 0
            
            return {
                'success': True,
                'result': result
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def rename_result(self, result_id: str, new_name: str) -> bool:
        """é‡å‘½åå†å²è®°å½•"""
        try:
            if not new_name.strip():
                return False
                
            # æ·»åŠ æ—¶é—´æˆ³ä»¥é¿å…å†²çª
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            full_name = f"{new_name.strip()}_{timestamp}"
            
            # æ›´æ–°æ•°æ®åº“
            return db.update_evaluation_result_name(result_id, full_name)
            
        except Exception as e:
            print(f"é‡å‘½åç»“æœå¤±è´¥: {e}")
            return False
    
    def delete_result(self, result_id: str) -> Dict:
        """åˆ é™¤å†å²è®°å½•å’Œå¯¹åº”çš„CSVæ–‡ä»¶"""
        try:
            # è·å–ç»“æœä¿¡æ¯
            detail = self.get_result_detail(result_id)
            if not detail['success']:
                return detail
            
            result = detail['result']
            deleted_files = []
            
            # åˆ é™¤æ‰€æœ‰ç›¸å…³çš„CSVæ–‡ä»¶
            file_path = result['result_file']
            result_name = result['name']
            
            print(f"ğŸ—‘ï¸ å¼€å§‹åˆ é™¤è¯„æµ‹ç»“æœ: {result_name} (ID: {result_id})")
            
            # 1. åˆ é™¤åŸå§‹æ–‡ä»¶è·¯å¾„æŒ‡å‘çš„æ–‡ä»¶
            if file_path:
                if os.path.isabs(file_path):
                    # ç»å¯¹è·¯å¾„
                    if os.path.exists(file_path):
                        os.remove(file_path)
                        deleted_files.append(file_path)
                        print(f"âœ… åˆ é™¤åŸå§‹æ–‡ä»¶: {file_path}")
                else:
                    # ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•å¤šä¸ªå¯èƒ½çš„ä½ç½®
                    possible_paths = [
                        file_path,  # åŸå§‹ç›¸å¯¹è·¯å¾„
                        os.path.join('results', os.path.basename(file_path)),
                        os.path.join('results_history', os.path.basename(file_path)),
                        os.path.join('results', file_path),
                        os.path.join('results_history', file_path)
                    ]
                    
                    for path in possible_paths:
                        if os.path.exists(path):
                            os.remove(path)
                            deleted_files.append(path)
                            print(f"âœ… åˆ é™¤æ–‡ä»¶: {path}")
            
            # 2. æ ¹æ®ç»“æœåç§°æŸ¥æ‰¾å¯èƒ½çš„æ–‡ä»¶
            # ç”Ÿæˆå¯èƒ½çš„æ–‡ä»¶åæ¨¡å¼
            base_name = result_name.replace(' ', '_')  # æ›¿æ¢ç©ºæ ¼ä¸ºä¸‹åˆ’çº¿
            possible_filenames = [
                f"{base_name}.csv",
                f"{result_name}.csv",
                f"evaluation_result_{result_name}.csv",
                # å¤„ç†å¯èƒ½çš„æ—¶é—´æˆ³åç¼€
                f"{base_name}*.csv",
            ]
            
            # æœç´¢å¯èƒ½çš„ç›®å½•
            search_dirs = ['results', 'results_history', '.']
            
            for search_dir in search_dirs:
                if not os.path.exists(search_dir):
                    continue
                    
                try:
                    for filename in os.listdir(search_dir):
                        if filename.endswith('.csv'):
                            # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ¹é…
                            for pattern in possible_filenames:
                                if pattern.endswith('*.csv'):
                                    # æ¨¡ç³ŠåŒ¹é…
                                    pattern_prefix = pattern[:-5]  # ç§»é™¤ '*.csv'
                                    if filename.startswith(pattern_prefix):
                                        file_full_path = os.path.join(search_dir, filename)
                                        if file_full_path not in deleted_files:
                                            os.remove(file_full_path)
                                            deleted_files.append(file_full_path)
                                            print(f"âœ… åˆ é™¤åŒ¹é…æ–‡ä»¶: {file_full_path}")
                                else:
                                    # ç²¾ç¡®åŒ¹é…
                                    if filename == pattern:
                                        file_full_path = os.path.join(search_dir, filename)
                                        if file_full_path not in deleted_files:
                                            os.remove(file_full_path)
                                            deleted_files.append(file_full_path)
                                            print(f"âœ… åˆ é™¤åŒ¹é…æ–‡ä»¶: {file_full_path}")
                except OSError as e:
                    print(f"âš ï¸ æœç´¢ç›®å½• {search_dir} æ—¶å‡ºé”™: {e}")
                    continue
            
            # 3. ä»æ•°æ®åº“åˆ é™¤ï¼ˆæ ‡è®°ä¸ºå·²åˆ é™¤ï¼‰
            with db._get_connection() as conn:
                db_cursor = conn.cursor()
                db_cursor.execute(
                    'UPDATE evaluation_results SET status = "deleted", archived_at = CURRENT_TIMESTAMP WHERE id = ?',
                    (result_id,)
                )
                conn.commit()
            
            if deleted_files:
                file_list = '\n'.join([f"  - {f}" for f in deleted_files])
                print(f"âœ… è¯„æµ‹ç»“æœåˆ é™¤å®Œæˆï¼Œå…±åˆ é™¤ {len(deleted_files)} ä¸ªæ–‡ä»¶:\n{file_list}")
                return {
                    'success': True, 
                    'message': f'åˆ é™¤æˆåŠŸï¼Œå…±åˆ é™¤ {len(deleted_files)} ä¸ªç›¸å…³æ–‡ä»¶',
                    'deleted_files': deleted_files
                }
            else:
                print(f"âœ… è¯„æµ‹ç»“æœä»æ•°æ®åº“åˆ é™¤å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç›¸å…³çš„CSVæ–‡ä»¶")
                return {
                    'success': True, 
                    'message': 'åˆ é™¤æˆåŠŸï¼ˆæœªæ‰¾åˆ°ç›¸å…³æ–‡ä»¶ï¼‰',
                    'deleted_files': []
                }
            
        except Exception as e:
            print(f"âŒ åˆ é™¤è¯„æµ‹ç»“æœå¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    def archive_old_results(self, days_threshold: int = 90) -> Dict:
        """å½’æ¡£æ—§ç»“æœ"""
        try:
            archived_count = db.archive_old_results(days_threshold)
            
            # ç§»åŠ¨æ–‡ä»¶åˆ°å½’æ¡£ç›®å½•
            archived_results = db.get_evaluation_history(status='archived', limit=1000)
            moved_files = 0
            
            for result in archived_results:
                if os.path.exists(result['result_file']):
                    filename = os.path.basename(result['result_file'])
                    archive_path = os.path.join(self.results_dir, "archived", filename)
                    shutil.move(result['result_file'], archive_path)
                    
                    # æ›´æ–°æ•°æ®åº“ä¸­çš„æ–‡ä»¶è·¯å¾„
                    with db._get_connection() as conn:
                        db_cursor = conn.cursor()
                        db_cursor.execute(
                            'UPDATE evaluation_results SET result_file = ? WHERE id = ?',
                            (archive_path, result['id'])
                        )
                        conn.commit()
                    moved_files += 1
            
            return {
                'success': True,
                'archived_count': archived_count,
                'moved_files': moved_files
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def add_tags(self, result_id: str, tags: List[str]) -> Dict:
        """ä¸ºç»“æœæ·»åŠ æ ‡ç­¾"""
        try:
            # è·å–å½“å‰æ ‡ç­¾
            detail = self.get_result_detail(result_id)
            if not detail['success']:
                return detail
            
            current_tags = set(detail['result']['tags'])
            new_tags = current_tags.union(set(tags))
            
            # æ›´æ–°æ•°æ®åº“
            with db._get_connection() as conn:
                db_cursor = conn.cursor()
                db_cursor.execute(
                    'UPDATE evaluation_results SET tags = ? WHERE id = ?',
                    (json.dumps(list(new_tags)), result_id)
                )
                conn.commit()
            
            return {'success': True, 'tags': list(new_tags)}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def get_available_tags(self) -> List[str]:
        """è·å–æ‰€æœ‰å¯ç”¨æ ‡ç­¾"""
        try:
            results = db.get_evaluation_history(limit=1000)
            all_tags = set()
            
            for result in results:
                all_tags.update(result['tags'])
            
            return sorted(list(all_tags))
            
        except Exception as e:
            return []
    
    def get_statistics(self) -> Dict:
        """è·å–å†å²ç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats = db.get_statistics()
            
            # æ·»åŠ ç£ç›˜ä½¿ç”¨ç»Ÿè®¡
            total_size = 0
            file_count = 0
            
            for root, dirs, files in os.walk(self.results_dir):
                for file in files:
                    if file.endswith('.csv'):
                        file_path = os.path.join(root, file)
                        if os.path.exists(file_path):
                            total_size += os.path.getsize(file_path)
                            file_count += 1
            
            stats.update({
                'total_disk_usage': self._format_file_size(total_size),
                'total_result_files': file_count,
                'available_tags_count': len(self.get_available_tags())
            })
            
            return stats
            
        except Exception as e:
            return {'error': str(e)}
    
    def _generate_result_summary(self, result_file: str, evaluation_data: Dict) -> Dict:
        """ç”Ÿæˆç»“æœæ‘˜è¦ç»Ÿè®¡"""
        try:
            df = pd.read_csv(result_file)
            
            summary = {
                'total_questions': int(len(df)),
                'models': evaluation_data.get('models', []),
                'evaluation_mode': evaluation_data.get('evaluation_mode'),
                'question_types': {},
                'model_scores': {},
                # æ·»åŠ æ—¶é—´ä¿¡æ¯
                'start_time': evaluation_data.get('start_time'),
                'end_time': evaluation_data.get('end_time'),
                'question_count': evaluation_data.get('question_count', len(df))
            }
            
            # ç»Ÿè®¡é¢˜ç›®ç±»å‹åˆ†å¸ƒ
            if 'ç±»å‹' in df.columns:
                type_counts = df['ç±»å‹'].value_counts()
                # è½¬æ¢ä¸ºPythonåŸç”Ÿæ•°æ®ç±»å‹
                summary['question_types'] = {str(k): int(v) for k, v in type_counts.items()}
            
            # ç»Ÿè®¡æ¨¡å‹è¯„åˆ†
            score_columns = [col for col in df.columns if 'è¯„åˆ†' in col]
            for col in score_columns:
                if col in df.columns:
                    model_name = col.replace('_è¯„åˆ†', '').replace('è¯„åˆ†', '')
                    scores = df[col].dropna()
                    if len(scores) > 0:
                        summary['model_scores'][model_name] = {
                            'avg_score': float(scores.mean()),
                            'max_score': float(scores.max()),
                            'min_score': float(scores.min()),
                            'scored_count': int(len(scores))
                        }
            
            return summary
            
        except Exception as e:
            return {'error': str(e)}
    
    def _generate_auto_tags(self, evaluation_data: Dict, result_summary: Dict) -> List[str]:
        """è‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾"""
        tags = []
        
        # åŸºäºè¯„æµ‹æ¨¡å¼
        mode = evaluation_data.get('evaluation_mode')
        if mode:
            tags.append(f"æ¨¡å¼_{mode}")
        
        # åŸºäºæ¨¡å‹æ•°é‡
        model_count = len(evaluation_data.get('models', []))
        if model_count == 1:
            tags.append("å•æ¨¡å‹")
        elif model_count > 1:
            tags.append("å¤šæ¨¡å‹å¯¹æ¯”")
        
        # åŸºäºé¢˜ç›®æ•°é‡
        total_questions = result_summary.get('total_questions', 0)
        if total_questions < 10:
            tags.append("å°è§„æ¨¡æµ‹è¯•")
        elif total_questions < 100:
            tags.append("ä¸­ç­‰è§„æ¨¡")
        else:
            tags.append("å¤§è§„æ¨¡æµ‹è¯•")
        
        # åŸºäºæ—¶é—´
        now = datetime.now()
        tags.append(f"{now.year}å¹´{now.month}æœˆ")
        
        return tags
    
    def _get_default_project_id(self) -> str:
        """è·å–é»˜è®¤é¡¹ç›®ID"""
        # ç®€å•å®ç°ï¼šæ€»æ˜¯è¿”å›ç¬¬ä¸€ä¸ªé¡¹ç›®æˆ–åˆ›å»ºé»˜è®¤é¡¹ç›®
        try:
            with db._get_connection() as conn:
                db_cursor = conn.cursor()
                db_cursor.execute('SELECT id FROM projects LIMIT 1')
                result = db_cursor.fetchone()
                
                if result:
                    return result[0]
                else:
                    # åˆ›å»ºé»˜è®¤é¡¹ç›®
                    return db.create_project("é»˜è®¤é¡¹ç›®", "ç³»ç»Ÿé»˜è®¤é¡¹ç›®")
        except:
            return "default"
    
    def _get_file_size(self, file_path: str) -> str:
        """è·å–æ–‡ä»¶å¤§å°ï¼ˆæ ¼å¼åŒ–ï¼‰"""
        try:
            if os.path.exists(file_path):
                size = os.path.getsize(file_path)
                return self._format_file_size(size)
            return "0 B"
        except:
            return "æœªçŸ¥"
    
    def _format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes == 0:
            return "0 B"
        
        size_names = ["B", "KB", "MB", "GB"]
        i = 0
        size = float(size_bytes)
        
        while size >= 1024.0 and i < len(size_names) - 1:
            size /= 1024.0
            i += 1
        
        return f"{size:.1f} {size_names[i]}"


# åˆ›å»ºå…¨å±€å†å²ç®¡ç†å™¨å®ä¾‹
history_manager = EvaluationHistoryManager()

if __name__ == "__main__":
    # æµ‹è¯•åŠŸèƒ½
    print("æµ‹è¯•è¯„æµ‹å†å²ç®¡ç†ç³»ç»Ÿ...")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = history_manager.get_statistics()
    print(f"ç³»ç»Ÿç»Ÿè®¡: {stats}")
    
    # è·å–å†å²åˆ—è¡¨
    history = history_manager.get_history_list()
    print(f"å†å²è®°å½•æ•°é‡: {len(history['results'])}")
    
    print("æµ‹è¯•å®Œæˆï¼")
