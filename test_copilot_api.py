#!/usr/bin/env python3
"""
æµ‹è¯•Copilot APIè°ƒç”¨å¹¶æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
ç”¨äºè°ƒè¯•"æ— æœ‰æ•ˆå†…å®¹è¿”å›"é—®é¢˜
"""

import os
import sys
import json
import asyncio
import aiohttp
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/Users/guozhenhua/PycharmProjects/model-evaluation-web')

# è®¾ç½®Cookieç¯å¢ƒå˜é‡
os.environ['COPILOT_COOKIE_PROD'] = 'passport=MTc1NjE5NzQ3NnxEWDhFQVFMX2dBQUJFQUVRQUFEX3h2LUFBQUVHYzNSeWFXNW5EQVVBQTJwM2RBWnpkSEpwYm1jTV82b0FfNmRsZVVwb1lrZGphVTlwU2tsVmVra3hUbWxKYzBsdVVqVmpRMGsyU1d0d1dGWkRTamt1WlhsS1dVeFZSbmRqUXpGS1drTkpOazFwZDJsYVdHaDNTV3B2ZUU1NlZUUk9lbWMxVGtSak1reERTbkJhUjFaMVpFZHNNR1ZUU1RaSmFrVTFUa1JaZUUxRVVYaE5la0Y0VGxSQk1FMXFRVEJPUkVGcFpsRXVSSFJxZGtablowNU5Oa1I2ZERCNU5ITTJSMlp1U0ZKVmMyZ3haR2RtY0d4RVQyMUVjM1pNT0VGNVRRPT18SOjP0DDR0uZxVe4bmTrWgyBXeqtjXkhsBbneAYm6PZ0=; __TRACKER__USER_INFO__={"userUniqueId":"1841767668273647616","userId":"1841767668273647616","webId":"38eab303-caf5-43a2-bb66-28ca74981314"}; copilot_prd=MTc1NjIwMDk3NnxEWDhFQVFMX2dBQUJFQUVRQUFEX3h2LUFBQUVHYzNSeWFXNW5EQVVBQTJwM2RBWnpkSEpwYm1jTV82b0FfNmRsZVVwb1lrZGphVTlwU2tsVmVra3hUbWxKYzBsdVVqVmpRMGsyU1d0d1dGWkRTamt1WlhsS1dVeFZSbmRqUXpGS1drTkpOazFwZDJsYVdHaDNTV3B2ZUU1NlZUUk9lbXQ1VDFSak1reERTbkJhUjFaMVpFZHNNR1ZUU1RaSmFrVTBUa1JGYTA1cVl6Sk9hbWQ1VG5wTk1rNUVZekpOVkZscFpsRXVOamRyWTI1cGJHOTNiMnRxTTBZeGMwVnRObWw0VXpVeU9GaHVWWHB2WkRKcE1VWmlWV05aWVVab01BPT18iXfqTriIMvbQHt96ompsK0HtF1xEXrlNvpiRm9-EZag='

async def test_copilot_api():
    """æµ‹è¯•Copilot APIè°ƒç”¨"""
    print("ğŸ§ª Copilot APIè°ƒç”¨æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•é…ç½®
    test_cases = [
        {
            "name": "HKGAI-V1-PROD",
            "url": "https://copilot.hkgai.org/copilot/api/instruction/completion",
            "model": "HKGAI-V1",
            "cookie_env": "COPILOT_COOKIE_PROD",
            "query": "ä»‹ç»æ·±åº¦å­¦ä¹ "
        }
    ]
    
    for test_case in test_cases:
        print(f"\nğŸ”§ æµ‹è¯• {test_case['name']}")
        print(f"ğŸ“‹ URL: {test_case['url']}")
        print(f"ğŸ¤– Model: {test_case['model']}")
        print(f"â“ Query: {test_case['query']}")
        
        # è·å–Cookie
        cookie = os.getenv(test_case['cookie_env'])
        if not cookie:
            print(f"âŒ ç¼ºå°‘Cookieç¯å¢ƒå˜é‡: {test_case['cookie_env']}")
            continue
        
        print(f"ğŸª Cookie: {cookie[:50]}...")
        
        # æ„å»ºè¯·æ±‚
        headers = {
            "Content-Type": "application/json",
            "X-App-Id": "2",
            "Cookie": cookie
        }
        
        payload = {
            "key": "common_writing",
            "parameters": [
                {
                    "key": "user_instruction",
                    "value": test_case['query']
                },
                {
                    "key": "uploaded_rel",
                    "value": ""
                },
                {
                    "key": "with_search",
                    "value": "false"
                },
                {
                    "key": "files",
                    "value": "[]"
                }
            ],
            "model": test_case['model'],
            "stream": True
        }
        
        print(f"ğŸ“¤ Request Payload:")
        print(json.dumps(payload, ensure_ascii=False, indent=2))
        
        # å‘é€è¯·æ±‚
        try:
            timeout = aiohttp.ClientTimeout(total=60)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                print(f"\nâ° å‘é€è¯·æ±‚...")
                start_time = datetime.now()
                
                async with session.post(test_case['url'], headers=headers, json=payload) as resp:
                    elapsed = (datetime.now() - start_time).total_seconds()
                    print(f"ğŸ“Š å“åº”çŠ¶æ€: HTTP {resp.status}")
                    print(f"â±ï¸ å“åº”æ—¶é—´: {elapsed:.2f}ç§’")
                    
                    if resp.status == 200:
                        # è·å–åŸå§‹å“åº”æ–‡æœ¬
                        raw_response = await resp.text()
                        print(f"ğŸ“„ åŸå§‹å“åº”é•¿åº¦: {len(raw_response)} å­—ç¬¦")
                        
                        # ä¿å­˜åŸå§‹å“åº”åˆ°æ–‡ä»¶
                        with open(f"raw_response_{test_case['name']}.txt", 'w', encoding='utf-8') as f:
                            f.write(raw_response)
                        print(f"ğŸ’¾ åŸå§‹å“åº”å·²ä¿å­˜åˆ°: raw_response_{test_case['name']}.txt")
                        
                        # æ˜¾ç¤ºå‰500å­—ç¬¦
                        print(f"\nğŸ“‹ åŸå§‹å“åº”å‰500å­—ç¬¦:")
                        print("=" * 40)
                        print(raw_response[:500])
                        print("=" * 40)
                        
                        # è§£æå“åº”
                        print(f"\nğŸ” è§£æå“åº”å†…å®¹...")
                        content = extract_copilot_content(raw_response.splitlines())
                        print(f"âœ… è§£æç»“æœé•¿åº¦: {len(content)} å­—ç¬¦")
                        
                        if content.strip():
                            print(f"ğŸ“ è§£æå†…å®¹å‰200å­—ç¬¦:")
                            print("=" * 40)
                            print(content[:200])
                            print("=" * 40)
                        else:
                            print("âŒ è§£æåæ— æœ‰æ•ˆå†…å®¹")
                            
                        # åˆ†æå“åº”ç»“æ„
                        analyze_response_structure(raw_response)
                        
                    else:
                        error_text = await resp.text()
                        print(f"âŒ è¯·æ±‚å¤±è´¥: HTTP {resp.status}")
                        print(f"ğŸ“„ é”™è¯¯å†…å®¹: {error_text[:200]}...")
                        
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()

def extract_copilot_content(stream: list) -> str:
    """æå–Copilotæµå¼å“åº”çš„å†…å®¹ï¼ˆå¢å¼ºè°ƒè¯•ç‰ˆæœ¬ï¼‰"""
    print(f"\nğŸ” å¼€å§‹è§£ææµå¼å“åº”ï¼Œå…± {len(stream)} è¡Œ")
    
    buffer = []
    current_event = None
    append_count = 0
    finish_count = 0
    
    for i, raw_line in enumerate(stream):
        line = raw_line.strip()
        if not line:
            continue
        
        print(f"  è¡Œ {i:3d}: {line[:100]}{'...' if len(line) > 100 else ''}")
        
        if line.startswith("event:"):
            current_event = line[len("event:"):].strip()
            print(f"    â–¶ï¸ äº‹ä»¶ç±»å‹: {current_event}")
            continue
        
        if line.startswith("data:") and current_event == "APPEND":
            append_count += 1
            json_part = line[len("data:"):].strip()
            print(f"    ğŸ“Š APPENDæ•°æ®: {json_part[:100]}{'...' if len(json_part) > 100 else ''}")
            
            try:
                payload = json.loads(json_part)
                
                # æå–choices[0].delta.content
                choices = payload.get("choices", [])
                if choices and len(choices) > 0:
                    delta = choices[0].get("delta", {})
                    content = delta.get("content", "")
                    if content:
                        buffer.append(content)
                        print(f"    âœ… æå–å†…å®¹: {repr(content)}")
                    else:
                        print(f"    âš ï¸ Deltaä¸­æ— contentå­—æ®µ")
                else:
                    print(f"    âš ï¸ æ— choicesæ•°æ®")
                    
            except json.JSONDecodeError as e:
                print(f"    âŒ JSONè§£æå¤±è´¥: {e}")
                continue
            except (KeyError, IndexError, TypeError) as e:
                print(f"    âŒ æ•°æ®ç»“æ„è§£æå¤±è´¥: {e}")
                continue
        
        elif line.startswith("data:") and current_event == "FINISH":
            finish_count += 1
            print(f"    ğŸ FINISHäº‹ä»¶")
            break
        
        elif line.startswith("data:"):
            print(f"    â„¹ï¸ å…¶ä»–äº‹ä»¶ç±»å‹ {current_event}: {line[:100]}")
    
    result = "".join(buffer)
    print(f"\nğŸ“Š è§£æç»Ÿè®¡:")
    print(f"  APPENDäº‹ä»¶: {append_count} ä¸ª")
    print(f"  FINISHäº‹ä»¶: {finish_count} ä¸ª")
    print(f"  æå–ç‰‡æ®µ: {len(buffer)} ä¸ª")
    print(f"  æ€»å­—ç¬¦æ•°: {len(result)}")
    
    return result

def analyze_response_structure(raw_response: str) -> None:
    """åˆ†æå“åº”ç»“æ„"""
    print(f"\nğŸ” å“åº”ç»“æ„åˆ†æ:")
    
    lines = raw_response.splitlines()
    event_types = {}
    data_lines = 0
    
    current_event = None
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        if line.startswith("event:"):
            event_type = line[len("event:"):].strip()
            event_types[event_type] = event_types.get(event_type, 0) + 1
            current_event = event_type
        elif line.startswith("data:"):
            data_lines += 1
            
            # å°è¯•è§£æJSON
            json_part = line[len("data:"):].strip()
            if json_part and current_event:
                try:
                    data = json.loads(json_part)
                    print(f"  ğŸ“‹ {current_event} æ•°æ®ç»“æ„: {list(data.keys())}")
                    
                    if current_event == "APPEND" and "choices" in data:
                        choices = data["choices"]
                        if choices and len(choices) > 0:
                            choice = choices[0]
                            print(f"    Choiceå­—æ®µ: {list(choice.keys())}")
                            if "delta" in choice:
                                delta = choice["delta"]
                                print(f"    Deltaå­—æ®µ: {list(delta.keys())}")
                except:
                    pass
    
    print(f"  æ€»è¡Œæ•°: {len(lines)}")
    print(f"  æ•°æ®è¡Œ: {data_lines}")
    print(f"  äº‹ä»¶ç±»å‹: {event_types}")

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨Copilot APIæµ‹è¯•")
    asyncio.run(test_copilot_api())
    print("\nâœ… æµ‹è¯•å®Œæˆ")
