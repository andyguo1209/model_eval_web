import os
import json
import uuid
import asyncio
import aiohttp
import pandas as pd
import time
import re
import csv
from datetime import datetime
from flask import Flask, render_template, request, jsonify, send_file, redirect, url_for
from werkzeug.utils import secure_filename
import google.generativeai as genai
from typing import Dict, Any, List, Optional
import threading
from utils.env_manager import env_manager

app = Flask(__name__)
app.config['SECRET_KEY'] = 'model-evaluation-web-2024'
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['RESULTS_FOLDER'] = 'results'
app.config['DATA_FOLDER'] = 'data'

# ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
for folder in [app.config['UPLOAD_FOLDER'], app.config['RESULTS_FOLDER'], app.config['DATA_FOLDER']]:
    os.makedirs(folder, exist_ok=True)

# æ”¯æŒçš„æ¨¡å‹é…ç½®
SUPPORTED_MODELS = {
    "HKGAI-V1": {
        "url": "https://chat.hkchat.app/goapi/v1/chat/stream",
        "model": "HKGAI-V1",
        "token_env": "ARK_API_KEY_HKGAI_V1",
        "headers_template": {
            "Accept": "text/event-stream",
            "Content-Type": "application/json"
        }
    },
    "HKGAI-V2": {
        "url": "https://chat.hkchat.app/goapi/v1/chat/stream",
        "model": "HKGAI-V2", 
        "token_env": "ARK_API_KEY_HKGAI_V2",
        "headers_template": {
            "Accept": "text/event-stream",
            "Content-Type": "application/json"
        }
    }
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šæ¨¡å‹
}

# Google APIé…ç½®
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

# å…¨å±€ä»»åŠ¡çŠ¶æ€ç®¡ç†
task_status = {}

class TaskStatus:
    def __init__(self, task_id):
        self.task_id = task_id
        self.status = "å¾…å¼€å§‹"
        self.progress = 0
        self.total = 0
        self.current_step = ""
        self.result_file = ""
        self.error_message = ""
        self.evaluation_mode = ""
        self.selected_models = []
        self.start_time = datetime.now()

def extract_stream_content(stream) -> str:
    """æå–HKGAIæµå¼å“åº”çš„å†…å®¹"""
    buffer = []
    current_event = None

    for raw_line in stream:
        line = raw_line.strip()
        if not line:
            continue

        if line.startswith("event:"):
            current_event = line[len("event:"):].strip()
            continue

        if line.startswith("data:") and current_event == "message":
            json_part = line[len("data:"):].strip()
            try:
                payload = json.loads(json_part)
                content = payload.get("content", "")
                if content:
                    buffer.append(content)
            except json.JSONDecodeError:
                continue

    return "".join(buffer)

async def fetch_model_answer(session: aiohttp.ClientSession, query: str, model_config: dict, idx: int, sem_model: asyncio.Semaphore, task_id: str, request_headers: dict = None) -> str:
    """è·å–å•ä¸ªæ¨¡å‹çš„ç­”æ¡ˆ"""
    # å…ˆä»ç¯å¢ƒå˜é‡è·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»è¯·æ±‚å¤´è·å–
    token = os.getenv(model_config["token_env"])
    if not token and request_headers:
        model_name = model_config["model"]
        token = request_headers.get(f'X-{model_name.replace("-", "-")}-Key')
    
    if not token:
        return f"é”™è¯¯ï¼šæœªé…ç½® {model_config['token_env']} APIå¯†é’¥"

    headers = model_config["headers_template"].copy()
    headers["Authorization"] = f"Bearer {token}"

    payload = {
        "model": model_config["model"],
        "features": {"web_search": False},
        "query": query,
        "chat_id": str(uuid.uuid4())
    }

    async with sem_model:
        try:
            async with session.post(model_config["url"], headers=headers, json=payload, timeout=60) as resp:
                if resp.status == 200:
                    raw = await resp.text()
                    content = extract_stream_content(raw.splitlines())
                    
                    # æ›´æ–°è¿›åº¦
                    if task_id in task_status:
                        task_status[task_id].progress += 1
                        task_status[task_id].current_step = f"å·²å®Œæˆ {task_status[task_id].progress}/{task_status[task_id].total} ä¸ªæŸ¥è¯¢"
                    
                    return content if content.strip() else "æ— æœ‰æ•ˆå†…å®¹è¿”å›"
                else:
                    return f"è¯·æ±‚å¤±è´¥: HTTP {resp.status}"
        except Exception as e:
            return f"è¯·æ±‚å¼‚å¸¸: {str(e)}"

async def get_multiple_model_answers(queries: List[str], selected_models: List[str], task_id: str, request_headers: dict = None) -> Dict[str, List[str]]:
    """è·å–å¤šä¸ªæ¨¡å‹çš„ç­”æ¡ˆ"""
    connector = aiohttp.TCPConnector(limit_per_host=10)
    timeout = aiohttp.ClientTimeout(total=60)
    sem_model = asyncio.Semaphore(5)  # æ§åˆ¶å¹¶å‘æ•°

    results = {model: [] for model in selected_models}
    
    if task_id in task_status:
        task_status[task_id].total = len(queries) * len(selected_models)
        task_status[task_id].status = "è·å–æ¨¡å‹ç­”æ¡ˆä¸­"

    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºä»»åŠ¡
        for model_name in selected_models:
            if model_name not in SUPPORTED_MODELS:
                continue
                
            model_config = SUPPORTED_MODELS[model_name]
            tasks = []
            
            for i, query in enumerate(queries):
                tasks.append(fetch_model_answer(session, query, model_config, i, sem_model, task_id, request_headers))
            
            # è·å–è¯¥æ¨¡å‹çš„æ‰€æœ‰ç­”æ¡ˆ
            answers = await asyncio.gather(*tasks)
            results[model_name] = answers

    return results

def detect_evaluation_mode(df: pd.DataFrame) -> str:
    """è‡ªåŠ¨æ£€æµ‹è¯„æµ‹æ¨¡å¼"""
    if 'answer' in df.columns:
        return 'objective'  # å®¢è§‚é¢˜è¯„æµ‹
    else:
        return 'subjective'  # ä¸»è§‚é¢˜è¯„æµ‹

def parse_json_str(s: str) -> Dict[str, Any]:
    """è§£æJSONå­—ç¬¦ä¸²"""
    s = (s or "").strip()
    if not s:
        return {}
    try:
        return json.loads(s)
    except json.JSONDecodeError:
        return {}



async def query_gemini_model(prompt: str, api_key: str = None) -> str:
    """æŸ¥è¯¢Geminiæ¨¡å‹"""
    def call_model():
        # ä½¿ç”¨ä¼ å…¥çš„APIå¯†é’¥æˆ–é»˜è®¤å¯†é’¥
        if api_key:
            genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-pro')
        resp = model.generate_content(prompt)
        return resp.text if resp and resp.text else ""
    
    return await asyncio.to_thread(call_model)

def build_subjective_eval_prompt(query: str, answers: Dict[str, str], question_type: str = "") -> str:
    """æ„å»ºä¸»è§‚é¢˜è¯„æµ‹æç¤º"""
    type_context = f"é—®é¢˜ç±»å‹: {question_type}\n" if question_type else ""
    
    models_text = ""
    for i, (model_name, answer) in enumerate(answers.items(), 1):
        models_text += f"æ¨¡å‹{i}({model_name})å›ç­”: {answer}\n\n"
    
    model_keys = list(answers.keys())
    json_format = {f"æ¨¡å‹{i+1}": {"è¯„åˆ†": "0-5", "ç†ç”±": "è¯„åˆ†ç†ç”±"} for i in range(len(model_keys))}
    
    return f"""
è¯·å¯¹ä»¥ä¸‹AIæ¨¡å‹å›ç­”è¿›è¡Œä¸»è§‚è´¨é‡è¯„åˆ†ï¼ˆ0-5åˆ†ï¼Œæ•´æ•°ï¼‰ã€‚

{type_context}é—®é¢˜: {query}

{models_text}

è¯„åˆ†æ ‡å‡†:
- 5åˆ†: å›ç­”ä¼˜ç§€ï¼Œé€»è¾‘æ¸…æ™°ï¼Œå†…å®¹ä¸°å¯Œ
- 4åˆ†: å›ç­”è‰¯å¥½ï¼ŒåŸºæœ¬ç¬¦åˆè¦æ±‚
- 3åˆ†: å›ç­”ä¸€èˆ¬ï¼Œæœ‰ä¸€å®šä»·å€¼
- 2åˆ†: å›ç­”è¾ƒå·®ï¼Œä»·å€¼æœ‰é™
- 1åˆ†: å›ç­”å¾ˆå·®ï¼Œå‡ ä¹æ— ä»·å€¼
- 0åˆ†: æ— å›ç­”æˆ–å®Œå…¨æ— å…³

åªè¾“å‡ºJSONæ ¼å¼ï¼Œä¸è¦å…¶ä»–æ–‡å­—: {json.dumps(json_format, ensure_ascii=False)}
"""

def build_objective_eval_prompt(query: str, standard_answer: str, answers: Dict[str, str], question_type: str = "") -> str:
    """æ„å»ºå®¢è§‚é¢˜è¯„æµ‹æç¤º"""
    type_context = f"é—®é¢˜ç±»å‹: {question_type}\n" if question_type else ""
    
    models_text = ""
    for i, (model_name, answer) in enumerate(answers.items(), 1):
        models_text += f"æ¨¡å‹{i}({model_name})å›ç­”: {answer}\n\n"
    
    model_keys = list(answers.keys())
    json_format = {f"æ¨¡å‹{i+1}": {"è¯„åˆ†": "0-5", "å‡†ç¡®æ€§": "æ­£ç¡®/éƒ¨åˆ†æ­£ç¡®/é”™è¯¯", "ç†ç”±": "è¯„åˆ†ç†ç”±"} for i in range(len(model_keys))}
    
    return f"""
è¯·å¯¹ç…§æ ‡å‡†ç­”æ¡ˆä¸ºAIæ¨¡å‹å›ç­”è¯„åˆ†ï¼ˆ0-5åˆ†ï¼Œæ•´æ•°ï¼‰ã€‚

{type_context}é—®é¢˜: {query}
æ ‡å‡†ç­”æ¡ˆ: {standard_answer}

{models_text}

è¯„åˆ†æ ‡å‡†:
- 5åˆ†: å®Œå…¨æ­£ç¡®ï¼Œè¡¨è¿°æ¸…æ™°
- 4åˆ†: åŸºæœ¬æ­£ç¡®ï¼Œç•¥æœ‰ç‘•ç–µ
- 3åˆ†: éƒ¨åˆ†æ­£ç¡®
- 2åˆ†: å¤§éƒ¨åˆ†é”™è¯¯ä½†æœ‰æ­£ç¡®å…ƒç´ 
- 1åˆ†: å®Œå…¨é”™è¯¯ä½†ç›¸å…³
- 0åˆ†: å®Œå…¨é”™è¯¯æˆ–æ— å…³

åªè¾“å‡ºJSONæ ¼å¼: {json.dumps(json_format, ensure_ascii=False)}
"""

def flatten_json(data: Dict[str, Any], prefix: str = "") -> Dict[str, Any]:
    """å¹³é“ºJSONå­—å…¸"""
    flat_data = {}
    for key, value in data.items():
        new_key = f"{prefix}_{key}" if prefix else key
        if isinstance(value, dict):
            flat_data.update(flatten_json(value, new_key))
        elif isinstance(value, list):
            flat_data[new_key] = str(value)
        else:
            flat_data[new_key] = value
    return flat_data

async def evaluate_models(data: List[Dict], mode: str, model_results: Dict[str, List[str]], task_id: str, google_api_key: str = None) -> str:
    """è¯„æµ‹æ¨¡å‹è¡¨ç°"""
    if task_id in task_status:
        task_status[task_id].status = "è¯„æµ‹ä¸­"
        task_status[task_id].total = len(data)
        task_status[task_id].progress = 0

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(app.config['RESULTS_FOLDER'], f"evaluation_result_{timestamp}.csv")
    
    # å‡†å¤‡CSVè¡¨å¤´
    model_names = list(model_results.keys())
    base_headers = ['åºå·', 'ç±»å‹', 'query']
    
    if mode == 'objective':
        base_headers.append('æ ‡å‡†ç­”æ¡ˆ')
    
    # åŠ¨æ€ç”Ÿæˆæ¨¡å‹ç›¸å…³çš„åˆ—
    eval_headers = []
    for i, model_name in enumerate(model_names, 1):
        eval_headers.extend([
            f'{model_name}_ç­”æ¡ˆ',
            f'{model_name}_è¯„åˆ†',
            f'{model_name}_ç†ç”±'
        ])
        if mode == 'objective':
            eval_headers.append(f'{model_name}_å‡†ç¡®æ€§')
    
    headers = base_headers + eval_headers
    
    with open(output_file, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(headers)
        
        for i, row in enumerate(data):
            query = str(row.get("query", ""))
            question_type = str(row.get("type", "æœªåˆ†ç±»"))
            standard_answer = str(row.get("answer", "")) if mode == 'objective' else ""
            
            # è·å–å„æ¨¡å‹çš„ç­”æ¡ˆ
            current_answers = {}
            for model_name in model_names:
                if i < len(model_results[model_name]):
                    current_answers[model_name] = model_results[model_name][i]
                else:
                    current_answers[model_name] = "è·å–ç­”æ¡ˆå¤±è´¥"
            
            # æ„å»ºè¯„æµ‹æç¤º
            if mode == 'objective':
                prompt = build_objective_eval_prompt(query, standard_answer, current_answers, question_type)
            else:
                prompt = build_subjective_eval_prompt(query, current_answers, question_type)
            
            try:
                gem_raw = await query_gemini_model(prompt, google_api_key)
                result_json = parse_json_str(gem_raw)
            except Exception as e:
                print(f"è¯„æµ‹ç¬¬{i+1}é¢˜æ—¶å‡ºé”™: {e}")
                result_json = {}
            
            # æ„é€ CSVè¡Œæ•°æ®
            row_data = [i+1, question_type, query]
            if mode == 'objective':
                row_data.append(standard_answer)
            
            # æ·»åŠ å„æ¨¡å‹çš„ç»“æœ
            for j, model_name in enumerate(model_names, 1):
                model_key = f"æ¨¡å‹{j}"
                row_data.append(current_answers[model_name])  # æ¨¡å‹ç­”æ¡ˆ
                
                if model_key in result_json:
                    row_data.append(result_json[model_key].get("è¯„åˆ†", ""))  # è¯„åˆ†
                    row_data.append(result_json[model_key].get("ç†ç”±", ""))  # ç†ç”±
                    if mode == 'objective':
                        row_data.append(result_json[model_key].get("å‡†ç¡®æ€§", ""))  # å‡†ç¡®æ€§
                else:
                    row_data.extend(["", ""])  # è¯„åˆ†ã€ç†ç”±
                    if mode == 'objective':
                        row_data.append("")  # å‡†ç¡®æ€§
            
            writer.writerow(row_data)
            
            # æ›´æ–°è¿›åº¦
            if task_id in task_status:
                task_status[task_id].progress += 1
                task_status[task_id].current_step = f"å·²è¯„æµ‹ {task_status[task_id].progress}/{task_status[task_id].total} é¢˜"

    return output_file

def run_async_task(func, *args):
    """åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥ä»»åŠ¡"""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        return loop.run_until_complete(func(*args))
    finally:
        loop.close()

@app.route('/')
def index():
    """é¦–é¡µ"""
    return render_template('index.html')

@app.route('/upload_file', methods=['POST'])
def upload_file():
    """ä¸Šä¼ è¯„æµ‹æ–‡ä»¶"""
    if 'file' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
    
    if file and file.filename.endswith(('.xlsx', '.xls', '.csv')):
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        try:
            # è¯»å–æ–‡ä»¶
            if filename.endswith('.csv'):
                df = pd.read_csv(filepath, encoding='utf-8-sig')
            else:
                df = pd.read_excel(filepath, engine='openpyxl')
            
            # æ£€æŸ¥å¿…éœ€åˆ—
            if 'query' not in df.columns:
                return jsonify({'error': 'æ–‡ä»¶å¿…é¡»åŒ…å«"query"åˆ—'}), 400
            
            # æ£€æµ‹è¯„æµ‹æ¨¡å¼
            mode = detect_evaluation_mode(df)
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_count = len(df)
            type_counts = df['type'].value_counts().to_dict() if 'type' in df.columns else {'æœªåˆ†ç±»': total_count}
            
            return jsonify({
                'success': True,
                'filename': filename,
                'mode': mode,
                'total_count': total_count,
                'type_counts': type_counts,
                'preview': df.head(5).to_dict('records'),
                'has_answer': 'answer' in df.columns,
                'has_type': 'type' in df.columns
            })
        except Exception as e:
            return jsonify({'error': f'æ–‡ä»¶è§£æé”™è¯¯: {str(e)}'}), 400
    
    return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼  .xlsxã€.xls æˆ– .csv æ–‡ä»¶'}), 400

@app.route('/get_available_models', methods=['GET'])
def get_available_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    models = []
    for model_name, config in SUPPORTED_MODELS.items():
        # å…ˆæ£€æŸ¥ç¯å¢ƒå˜é‡ï¼Œå†æ£€æŸ¥HTTPå¤´éƒ¨
        token = os.getenv(config["token_env"]) or request.headers.get(f'X-{model_name.replace("-", "-")}-Key')
        models.append({
            'name': model_name,
            'available': bool(token),
            'token_env': config["token_env"]
        })
    
    # æ£€æŸ¥Google APIå¯†é’¥
    google_key = GOOGLE_API_KEY or request.headers.get('X-Google-API-Key')
    
    return jsonify({
        'models': models,
        'gemini_available': bool(google_key)
    })

@app.route('/start_evaluation', methods=['POST'])
def start_evaluation():
    """å¼€å§‹è¯„æµ‹"""
    data = request.get_json()
    filename = data.get('filename')
    selected_models = data.get('selected_models', [])
    force_mode = data.get('force_mode')  # 'auto', 'subjective', 'objective'
    
    if not filename:
        return jsonify({'error': 'ç¼ºå°‘æ–‡ä»¶å'}), 400
    
    if not selected_models:
        return jsonify({'error': 'è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹'}), 400
    
    if not GOOGLE_API_KEY:
        return jsonify({'error': 'è¯·é…ç½®GOOGLE_API_KEYç¯å¢ƒå˜é‡'}), 400
    
    # æ£€æŸ¥é€‰ä¸­çš„æ¨¡å‹æ˜¯å¦å¯ç”¨
    for model_name in selected_models:
        if model_name not in SUPPORTED_MODELS:
            return jsonify({'error': f'ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}'}), 400
        
        token_env = SUPPORTED_MODELS[model_name]["token_env"]
        if not os.getenv(token_env):
            return jsonify({'error': f'æ¨¡å‹ {model_name} ç¼ºå°‘ç¯å¢ƒå˜é‡: {token_env}'}), 400
    
    filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
    if not os.path.exists(filepath):
        return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 400
    
    try:
        # è¯»å–æ–‡ä»¶
        if filename.endswith('.csv'):
            df = pd.read_csv(filepath, encoding='utf-8-sig')
        else:
            df = pd.read_excel(filepath, engine='openpyxl')
        
        # ç¡®å®šè¯„æµ‹æ¨¡å¼
        if force_mode == 'auto':
            mode = detect_evaluation_mode(df)
        else:
            mode = force_mode
        
        # éªŒè¯æ¨¡å¼å’Œæ•°æ®çš„åŒ¹é…
        if mode == 'objective' and 'answer' not in df.columns:
            return jsonify({'error': 'å®¢è§‚é¢˜è¯„æµ‹æ¨¡å¼éœ€è¦æ–‡ä»¶åŒ…å«"answer"åˆ—'}), 400
        
        # å¦‚æœæ²¡æœ‰typeåˆ—ï¼Œæ·»åŠ é»˜è®¤å€¼
        if 'type' not in df.columns:
            df['type'] = 'æœªåˆ†ç±»'
        
        data_list = df.to_dict('records')
        queries = [str(row['query']) for row in data_list]
        
        task_id = str(uuid.uuid4())
        task_status[task_id] = TaskStatus(task_id)
        task_status[task_id].evaluation_mode = mode
        task_status[task_id].selected_models = selected_models
        
        def task():
            try:
                # ä»è¯·æ±‚å¤´è·å–APIå¯†é’¥
                headers_dict = dict(request.headers)
                
                # ç¬¬ä¸€æ­¥ï¼šè·å–æ¨¡å‹ç­”æ¡ˆ
                model_results = run_async_task(get_multiple_model_answers, queries, selected_models, task_id, headers_dict)
                
                # ç¬¬äºŒæ­¥ï¼šè¯„æµ‹
                google_api_key = GOOGLE_API_KEY or request.headers.get('X-Google-API-Key')
                output_file = run_async_task(evaluate_models, data_list, mode, model_results, task_id, google_api_key)
                
                task_status[task_id].status = "å®Œæˆ"
                task_status[task_id].result_file = output_file
                task_status[task_id].current_step = f"è¯„æµ‹å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° {os.path.basename(output_file)}"
                
            except Exception as e:
                task_status[task_id].status = "å¤±è´¥"
                task_status[task_id].error_message = str(e)
        
        # åœ¨åå°è¿è¡Œä»»åŠ¡
        thread = threading.Thread(target=task)
        thread.start()
        
        return jsonify({'success': True, 'task_id': task_id})
        
    except Exception as e:
        return jsonify({'error': f'å¤„ç†é”™è¯¯: {str(e)}'}), 400

@app.route('/task_status/<task_id>')
def get_task_status(task_id):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    if task_id not in task_status:
        return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404
    
    task = task_status[task_id]
    elapsed_time = (datetime.now() - task.start_time).total_seconds()
    
    return jsonify({
        'status': task.status,
        'progress': task.progress,
        'total': task.total,
        'current_step': task.current_step,
        'result_file': os.path.basename(task.result_file) if task.result_file else "",
        'error_message': task.error_message,
        'evaluation_mode': task.evaluation_mode,
        'selected_models': task.selected_models,
        'elapsed_time': f"{elapsed_time:.1f}ç§’"
    })

@app.route('/download/<filename>')
def download_file(filename):
    """ä¸‹è½½ç»“æœæ–‡ä»¶"""
    filepath = os.path.join(app.config['RESULTS_FOLDER'], filename)
    if os.path.exists(filepath):
        return send_file(filepath, as_attachment=True)
    else:
        return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404

@app.route('/view_results/<filename>')
def view_results(filename):
    """æŸ¥çœ‹è¯„æµ‹ç»“æœ"""
    filepath = os.path.join(app.config['RESULTS_FOLDER'], filename)
    if not os.path.exists(filepath):
        return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
    
    try:
        df = pd.read_csv(filepath, encoding='utf-8-sig')
        return render_template('results.html', 
                             filename=filename,
                             columns=df.columns.tolist(),
                             data=df.to_dict('records'))
    except Exception as e:
        return jsonify({'error': f'è¯»å–ç»“æœæ–‡ä»¶é”™è¯¯: {str(e)}'}), 400


@app.route('/save_api_keys', methods=['POST'])
def save_api_keys():
    """ä¿å­˜APIå¯†é’¥åˆ°æœ¬åœ°.envæ–‡ä»¶"""
    try:
        data = request.get_json()
        
        # è·å–APIå¯†é’¥
        google_key = data.get('google_api_key', '').strip()
        hkgai_v1_key = data.get('hkgai_v1_key', '').strip()
        hkgai_v2_key = data.get('hkgai_v2_key', '').strip()
        
        # å‡†å¤‡è¦ä¿å­˜çš„ç¯å¢ƒå˜é‡
        env_vars_to_save = {}
        
        if google_key:
            env_vars_to_save['GOOGLE_API_KEY'] = google_key
        if hkgai_v1_key:
            env_vars_to_save['ARK_API_KEY_HKGAI_V1'] = hkgai_v1_key
        if hkgai_v2_key:
            env_vars_to_save['ARK_API_KEY_HKGAI_V2'] = hkgai_v2_key
        
        if not env_vars_to_save:
            return jsonify({
                'success': False,
                'message': 'æ²¡æœ‰æä¾›ä»»ä½•APIå¯†é’¥'
            })
        
        # ä¿å­˜åˆ°.envæ–‡ä»¶
        success = env_manager.save_env_vars(env_vars_to_save)
        
        if success:
            # é‡æ–°é…ç½®Google Generative AIï¼ˆå¦‚æœæœ‰Googleå¯†é’¥ï¼‰
            if google_key:
                genai.configure(api_key=google_key)
            
            return jsonify({
                'success': True,
                'message': f'å·²æˆåŠŸä¿å­˜{len(env_vars_to_save)}ä¸ªAPIå¯†é’¥åˆ°æœ¬åœ°æ–‡ä»¶',
                'saved_keys': list(env_vars_to_save.keys())
            })
        else:
            return jsonify({
                'success': False,
                'message': 'ä¿å­˜APIå¯†é’¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æƒé™'
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'ä¿å­˜APIå¯†é’¥æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}'
        })


@app.route('/get_env_status', methods=['GET'])
def get_env_status():
    """è·å–.envæ–‡ä»¶çŠ¶æ€ä¿¡æ¯"""
    try:
        env_path = env_manager.get_env_file_path()
        env_exists = env_manager.env_file_exists()
        
        saved_keys = []
        if env_exists:
            env_vars = env_manager.load_env()
            api_keys = ['GOOGLE_API_KEY', 'ARK_API_KEY_HKGAI_V1', 'ARK_API_KEY_HKGAI_V2']
            saved_keys = [key for key in api_keys if key in env_vars and env_vars[key]]
        
        return jsonify({
            'env_file_path': env_path,
            'env_file_exists': env_exists,
            'saved_keys': saved_keys,
            'total_saved': len(saved_keys)
        })
        
    except Exception as e:
        return jsonify({
            'error': f'è·å–ç¯å¢ƒçŠ¶æ€å¤±è´¥: {str(e)}'
        })


if __name__ == '__main__':
    print("ğŸš€ æ¨¡å‹è¯„æµ‹Webç³»ç»Ÿå¯åŠ¨ä¸­...")
    print("ğŸ“‹ è¯·ç¡®ä¿è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
    print("   - GOOGLE_API_KEY: Geminiè¯„æµ‹APIå¯†é’¥")
    print("   - ARK_API_KEY_HKGAI_V1: HKGAI-V1æ¨¡å‹APIå¯†é’¥")
    print("   - ARK_API_KEY_HKGAI_V2: HKGAI-V2æ¨¡å‹APIå¯†é’¥")
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:5001")
    app.run(debug=True, host='0.0.0.0', port=5001)
